"""
This module summarizes the functions used to generate the competencies.
It contains a multitude of functions that are used to extract competencies
from abstracts using different language models.
"""

import random
import galai as gal
from transformers import (XLNetTokenizer, XLNetForQuestionAnsweringSimple,
                          BloomForCausalLM, BloomTokenizerFast,
                          pipeline, AutoTokenizer, OPTForCausalLM)
from torch import argmax
from torch.nn import functional as F
from keybert import KeyBERT
from sentence_transformers import SentenceTransformer
from sklearn.metrics.pairwise import cosine_similarity

CATEGORIES = ["Mathematics", "Computer and Informations Sciences",
                  "Physical Sciences", "Chemical Sciences",
                  "Environmental Sciences",
                  "Earth Sciences", "Biological Sciences",
                  "Civil Engineering",
                  "Electrical Engineering", "Mechanical Engineering",
                  "Chemical Engineering", "Materials Engineering",
                  "Medical Engineering", "Nano-technology", "Medicine",
                  "Health Sciences", "Agriculture, Forestry, and Fisheries",
                  "Animal and Dairy Sciences", "Veterinary Sciences",
                  "Agricultural Engineering", "Psychology",
                  "Economics and Business",
                  "Educational Sciences", "Sociology",
                  "Law", "Political Sciences",
                  "Geography", "Media and Communication",
                  "History and Archeology",
                  "Languages and Literature", "Philosophy",
                  "Ethics and Religion"]


def get_competency_from_backend(abstract: str):
    """Returns a list of competencies using KeyBERT with optimized paramters.

    Args:
        abstract (str): A scientific abstract in text format

    Returns:
        list: list in the form of [(competency, score), ...]
    """
    kw_model = KeyBERT("distilbert-base-nli-mean-tokens")
    keywords = kw_model.extract_keywords(abstract,
                                         keyphrase_ngram_range=(1, 2),
                                         use_mmr=True, diversity=0.5)

    filtered_keywords = list(filter(lambda x: x[1] > 0.4, keywords))
    return filtered_keywords


def answer_abstract_question(abstract: str):
    """Answers the question "What is the most meaningful word in the text?"
    for a given abstract.

    Args:
        abstract (str): A scienfific abstract in text format

    Returns:
        json: The answer and the confidence of the model
    """
    context = abstract
    question = "What skill is mentioned in the text?"
    qa_model = pipeline("question-answering")
    answer = qa_model(question=question,
                      context=context, max_answer_length=5)

    return {"answer": answer["answer"], "confidence": answer["score"]}


def summarize(abstract: str):
    """Summarizes a given abstract

    Args:
        abstract (str): A scientific abstract in text format
    """
    summarizer = pipeline("summarization", model="google/pegasus-xsum")
    answer = summarizer(abstract, max_length=2000)[0]["summary_text"]
    return answer


def get_mock_competency():
    """Returns a mock competency

    Returns:
        str: A mock competency
    """
    competence_list = ["ner", "sentiment-analysis", "text-generation",
                       "text-classification", "question-answering",
                       "fill-mask", "summarization", "clonation",
                       "mathematics", "linear-algebra", "analysis"]

    return random.choice(competence_list)


def ask_galactica(abstract: str):
    """Returns galactica's answer to being asked what competencies an
    abstract author has.

    Args:
        abstract (str): A scientific abstract in text format

    Returns:
        list: A list of competencies generated by Galactica
    """
    model = gal.load_model(name="mini")

    prompt = f"Extract keywords from this abstract:{abstract} \n\n Keywords:"

    # Generate keywords and refactor them to list
    competency_list = model.generate(prompt,
                                     max_length=512).replace(prompt,
                                                             "").split(',')

    # Remove unnecessary whitespaces
    competency_list = [competency.strip() for competency in competency_list]

    # Remove duplicates
    competency_list = list(dict.fromkeys(competency_list))

    # Remove empty strings
    competency_list = list(filter(None, competency_list))

    # Remove competencies with more than 4 words
    competency_list = list(filter(lambda x: len(x.split()) < 5,
                                  competency_list))

    # If a competency is part of another competency, remove it
    for competency in competency_list:
        for other_competency in competency_list:
            if competency in other_competency and competency != other_competency:
                competency_list.remove(competency)

    competency_list = [(competency, -1.0) for competency in competency_list]
    return competency_list


def ask_xlnet(abstract: str):
    """Generates an answer to the question "What competency is mentioned in
    the abstract?" using XLNet.

    Args:
        abstract (str): A scientific abstract in text format

    Returns:
        list: A list of competencies generated by XLNet
    """
    tokenizer = XLNetTokenizer.from_pretrained("xlnet-base-cased")
    model = XLNetForQuestionAnsweringSimple.from_pretrained("xlnet-base-cased",
                                                            return_dict=True)
    question = "What skill is mentioned in the abstract?"
    inputs = tokenizer.encode_plus(question, abstract,
                                   return_tensors='pt')
    output = model(**inputs)
    start_max = argmax(F.softmax(output.start_logits, dim=-1))
    end_max = argmax(F.softmax(output.end_logits, dim=-1)) + 1
    # Add one because of python list indexing
    answer = tokenizer.decode(inputs["input_ids"][0][start_max: end_max])
    return answer


def ask_bloom(abstract: str, method: int):
    """Generates an answer to the question "What competency is mentioned in
    the abstract?" using Bloom. A method can be chosen to generate the
    answer. The methods are: 0: Greedy Search, 1: Beam Search, 2: Sampling

    Args:
        abstract (str): An abstract in text format
        method (int): The method to use for generating the answer
    """
    model = BloomForCausalLM.from_pretrained("bigscience/bloom-1b7")
    tokenizer = BloomTokenizerFast.from_pretrained("bigscience/bloom-1b7")
    question = "What competency is mentioned in the abstract?"
    prompt = abstract + question
    result_length = 50
    inputs = tokenizer(prompt, return_tensors="pt")

    if method == 0:
        # Greedy Search
        tokenizer.decode(model.generate(inputs["input_ids"],
                                        max_length=result_length)[0])
    elif method == 1:
        # Beam Search
        print(tokenizer.decode(model.generate(inputs["input_ids"],
                                              max_length=result_length,
                                              num_beams=2,
                                              no_repeat_ngram_size=2,
                                              early_stopping=True)[0]))
    elif method == 2:
        # Sampling Top-k + Top-p
        print(tokenizer.decode(model.generate(inputs["input_ids"],
                                              max_length=result_length,
                                              do_sample=True,
                                              top_k=50,
                                              top_p=0.9)[0]))


def ask_keybert(abstract: str):
    """Extracts keywords from an abstract using KeyBert.

    Args:
        abstract (str): A scientific abstract in text format

    Returns:
        list: [[keyword, relevancy], [keyword, relevancy], ...]
    """
    kw_model = KeyBERT()
    keywords = kw_model.extract_keywords(abstract,
                                         keyphrase_ngram_range=(1, 3))
    return keywords


def get_category_of_competency(competence: str):
    """Maps one of the 33 categories to a given competence based on
    the competence's similarity to the category's keywords.

    Args:
        competence (str): The string representation of a competence
    """
    competency_and_categories = [competence] + CATEGORIES
    model = SentenceTransformer("bert-base-nli-mean-tokens")
    categories_embeddings = model.encode(competency_and_categories)
    similarities = cosine_similarity([categories_embeddings[0]],
                                     categories_embeddings[1:])
    # Get index with maximum similarity, convertion to int, as fastapi
    # cant handle numpy int
    index = int(similarities[0].argmax())
    return index


def generate_text(abstract: str):
    """Generates text based on an abstract using GPT-Neo.

    Args:
        abstract (str): A scientific abstract in text format

    Returns:
        list: A list of generated texts
    """
    prompt = "The competencies of the person who wrote this abstract are:"
    generator = pipeline(
                         "text-generation",
                         model="EleutherAI/gpt-neo-2.7B",
                         min_length=100,
                         max_length=100
                         )
    return generator(abstract + prompt)
