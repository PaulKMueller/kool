"""Creates a streamlit app for the playground.
The playground is used to test the model_api and the database_api.
"""

import os
import requests
import streamlit as st
from pandas import DataFrame
import seaborn as sns
from download_button import download
from models import ask_xlnet


st.set_page_config(
    page_title="Kool - Competency Extractor",
    page_icon="ğŸ‘¨â€ğŸ”¬",
)


def _max_width_():
    max_width_str = "max-width: 1400px;"
    st.markdown(
        f"""
    <style>
    .reportview-container .main .block-container{{
        {max_width_str}
    }}
    </style>
    """,
        unsafe_allow_html=True,
    )


_max_width_()

c30, c31, c32 = st.columns([2.5, 1, 3])

with c30:
    st.title("â” XLNet 125M")
    st.header("")

with st.expander("â„¹ï¸ - About this interface", expanded=True):

    st.write(
        ("The *Kool - Competency Extractor* app is an easy-to-use "
            "interface built in [Streamlit](https://streamlit.io/)"
            " for the amazing [KeyBERT]"
            "(https://github.com/MaartenGr/KeyBERT) library from "
            "Maarten Grootendorst!\n"
            "It uses a minimal keyword extraction technique that "
            "leverages multiple NLP embeddings and relies on "
            "[Transformers](https://huggingface.co/transformers/) ğŸ¤— "
            "to extract competencies "
            "that are most similar to a document.")
    )

    st.markdown("")

st.markdown("")
st.markdown("## **ğŸ“Œ Paste document **")
with st.form(key="my_form"):

    ce, c1, c2, c3 = st.columns([0.07, 2, 5, 0.07])
    with c1:
        ModelType = st.radio(
            "Your model",
            ["XLNet",],
            help=("This is your chosen model."),
        )

    with c2:
        doc = st.text_area(
            "Paste your text below (max 1000 words)",
            height=510,
        )

        MAX_WORDS = 1000
        import re
        res = len(re.findall(r"\w+", doc))
        if res > MAX_WORDS:
            st.warning(
                "âš ï¸ Your text contains "
                + str(res)
                + " words."
                + (" Only the first 1000 words will be reviewed. Since this "
                   "application is supposed to be used for abstracts, please "
                   "limit your text to 1000 words.")
            )

            doc = doc[:MAX_WORDS]

        submit_button = st.form_submit_button(label="ğŸ“ˆ Get me the data!")

question = st.text_input("Your question:", value=("What keyword is"
                                                  " mentioned in "
                                                  "the abstract?"))

if not submit_button:
    st.stop()


keywords = []
if ModelType == "XLNet":
    keywords = ask_xlnet(abstract=doc, question=question)

st.header("Result:")
st.write(keywords)

# st.markdown("## **ğŸ” Check & download results **")

# st.header("")

# cs, c1, c2, c3, cLast = st.columns([2, 1.5, 1.5, 1.5, 2])

# with c1:
#     download(keywords, "Data.csv", "ğŸ“… Download (.csv)")
# with c2:
#     download(keywords, "Data.txt", "ğŸ“„ Download (.txt)")
# with c3:
#     download(keywords, "Data.json", "ğŸ“¥ Download (.json)")

# st.header("")

# df = (
#     DataFrame(keywords, columns=["Keyword/Keyphrase", "Relevancy"])
#     .sort_values(by="Relevancy", ascending=False)
#     .reset_index(drop=True)
# )

# df.index += 1

# # Add styling
# cmGreen = sns.light_palette("green", as_cmap=True)
# cmRed = sns.light_palette("red", as_cmap=True)
# df = df.style.background_gradient(
#     cmap=cmGreen,
#     subset=[
#         "Relevancy",
#     ],
# )

# c1, c2, c3 = st.columns([1, 3, 1])

# format_dictionary = {
#     "Relevancy": "{:.1%}",
# }

# df = df.format(format_dictionary)

# with c2:
#     st.table(df)
